{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ddc718e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd27bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import re\\n\\n# pylint: disable=R0401,C0302\\nfrom abc import ABC, abstractmethod\\nfrom copy import deepcopy\\nfrom dataclasses import dataclass, field, fields\\nfrom enum import Enum\\nfrom itertools import chain, zip_longest\\nfrom typing import (\\n    TYPE_CHECKING,\\n    Any,\\n    Callable,\\n    Generic,\\n    Iterator,\\n    List,\\n    Optional,\\n    Set,\\n    Tuple,\\n    Type,\\n    TypeVar,\\n    Union,\\n)\\n\\nfrom sqlmodel import Session\\n\\nfrom dj.models.database import Database\\nfrom dj.models.node import NodeRevision as DJNode\\nfrom dj.models.node import NodeType as DJNodeType\\nfrom dj.sql.functions import function_registry\\nfrom dj.sql.parsing.backends.exceptions import DJParseException\\nfrom dj.typing import ColumnType, ColumnTypeError\\nfrom datetime import timedelta\\n\\nif TYPE_CHECKING:\\n    from dj.construction.build_planning import BuildPlan  # type:ignore\\n\\nPRIMITIVES = {int, float, str, bool, type(None)}\\n\\n\\ndef flatten(maybe_iterables: Any) -> Iterator:\\n    \\\"\\\"\\\"\\n    Flattens `maybe_iterables` by descending into items that are Iterable\\n    \\\"\\\"\\\"\\n\\n    if not isinstance(maybe_iterables, (list, tuple, set, Iterator)):\\n        return iter([maybe_iterables])\\n    return chain.from_iterable(\\n        (flatten(maybe_iterable) for maybe_iterable in maybe_iterables)\\n    )\\n\\n\\ndef _raw_clean_hash(obj) -> str:\\n    \\\"\\\"\\\"\\n    Used to generate clean and unique replacement\\n     hash strings for Raw\\n\\n    >>> _raw_clean_hash(-2)\\n    'N2'\\n\\n    >>> _raw_clean_hash(1)\\n    '1'\\n    \\\"\\\"\\\"\\n    dirty = hash(obj)\\n    if dirty < 0:\\n        return f\\\"N{abs(dirty)}\\\"\\n    return str(dirty)\\n\\n\\nclass Replacer:  # pylint: disable=too-few-public-methods\\n    \\\"\\\"\\\"\\n    Replacer class keeps track of seen nodes\\n    and does the compare and replace calls\\n    while recursively calling `Node.replace`\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, compare: Optional[Callable[[Any, Any], bool]] = None):\\n        self._compare: Callable[[Any, Any], bool] = compare or (\\n            lambda a, b: a.compare(b) if isinstance(a, Node) else a == b\\n        )\\n\\n        self.seen: Set[\\n            int\\n        ] = (\\n            set()\\n        )  # to avoid infinite recursion from cycles ex. column->table->column...\\n\\n    def __call__(  # pylint: disable=too-many-branches,invalid-name\\n        self,\\n        self_node: \\\"Node\\\",\\n        from_: Any,\\n        to: Any,\\n    ):\\n        if id(self_node) in self.seen:\\n            return\\n        self.seen.add(id(self_node))\\n        for name, child in self_node.fields(\\n            flat=False,\\n            nodes_only=False,\\n            obfuscated=True,\\n            nones=False,\\n            named=True,\\n        ):\\n            iterable = False\\n            for iterable_type in (list, tuple, set):\\n                if isinstance(child, iterable_type):\\n                    iterable = True\\n                    new = []\\n                    for element in child:\\n                        if not self._compare(\\n                            element,\\n                            from_,\\n                        ):  # if the node is not a match, keep the old\\n                            new.append(element)\\n                        else:\\n                            new.append(to)\\n                        # recurse to other nodes in the iterable\\n                        if isinstance(element, Node):  # pragma: no cover\\n                            element.replace(from_, to, _replace=self)\\n                    new = iterable_type(new)  # type: ignore\\n                    setattr(self_node, name, new)\\n            if not iterable:\\n                if isinstance(child, Node):\\n                    if self._compare(child, from_):\\n                        setattr(self_node, name, to)\\n                else:\\n                    if self._compare(child, from_):\\n                        setattr(self_node, name, to)\\n            if isinstance(child, Node):\\n                child.replace(from_, to, _replace=self)\\n\\n\\nclass DJEnum(Enum):\\n    \\\"\\\"\\\"\\n    A DJ AST enum\\n    \\\"\\\"\\\"\\n\\n    def __repr__(self) -> str:\\n        return str(self)\\n\\n\\n# typevar used for node methods that return self\\n# so the typesystem can correlate the self type with the return type\\nTNode = TypeVar(\\\"TNode\\\", bound=\\\"Node\\\")  # pylint: disable=C0103\\n\\n\\nclass Node(ABC):\\n    \\\"\\\"\\\"Base class for all DJ AST nodes.\\n\\n    DJ nodes are python dataclasses with the following patterns:\\n        - Attributes are either\\n            - PRIMITIVES (int, float, str, bool, None)\\n            - iterable from (list, tuple, set)\\n            - Enum\\n            - descendant of `Node`\\n        - Attributes starting with '_' are \\\"obfuscated\\\" and are not included in `children`\\n\\n    \\\"\\\"\\\"\\n\\n    parent: Optional[\\\"Node\\\"] = None\\n    parent_key: Optional[str] = None\\n    validate_strict: Optional[bool] = True  # how to validate; `None` is no validation\\n    __instantiated = False\\n\\n    def __post_init__(self):\\n        self.add_self_as_parent()\\n        self.__instantiated = True\\n\\n    def validate(self):\\n        \\\"\\\"\\\"\\n        Validate a Node\\n        \\\"\\\"\\\"\\n\\n    def clear_parent(self: TNode) -> TNode:\\n        \\\"\\\"\\\"\\n        Remove parent from the node\\n        \\\"\\\"\\\"\\n        self.parent = None\\n        return self\\n\\n    def set_parent(self: TNode, parent: \\\"Node\\\", parent_key: str) -> TNode:\\n        \\\"\\\"\\\"\\n        Add parent to the node\\n        \\\"\\\"\\\"\\n        self.parent = parent\\n        self.parent_key = parent_key\\n        return self\\n\\n    def add_self_as_parent(self: TNode) -> TNode:\\n        \\\"\\\"\\\"\\n        Adds self as a parent to all children\\n        \\\"\\\"\\\"\\n        for name, child in self.fields(\\n            flat=True,\\n            nodes_only=True,\\n            obfuscated=False,\\n            nones=False,\\n            named=True,\\n        ):\\n            child.set_parent(self, name)\\n        return self\\n\\n    def __setattr__(self, key: str, value: Any):\\n        \\\"\\\"\\\"\\n        Facilitates setting children using `.` syntax ensuring parent is attributed\\n        \\\"\\\"\\\"\\n        if key == \\\"parent\\\":\\n            object.__setattr__(self, key, value)\\n            return\\n\\n        object.__setattr__(self, key, value)\\n        for child in flatten(value):\\n            if isinstance(child, Node) and not key.startswith(\\\"_\\\"):\\n                child.set_parent(self, key)\\n        # if node is not being instantiated for the first time let's validate\\n        if self.__instantiated:\\n            self.validate()\\n\\n    def copy(self: TNode) -> TNode:\\n        \\\"\\\"\\\"\\n        Create a deep copy of the `self`\\n        \\\"\\\"\\\"\\n        return deepcopy(self)\\n\\n    def get_nearest_parent_of_type(\\n        self: \\\"Node\\\",\\n        node_type: Type[TNode],\\n    ) -> Optional[TNode]:\\n        \\\"\\\"\\\"\\n        Traverse up the tree until you find a node of `node_type` or hit the root\\n        \\\"\\\"\\\"\\n        if isinstance(self.parent, node_type):\\n            return self.parent\\n        if self.parent is None:\\n            return None\\n        return self.parent.get_nearest_parent_of_type(node_type)\\n\\n    def flatten(self) -> Iterator[\\\"Node\\\"]:\\n        \\\"\\\"\\\"\\n        Flatten the sub-ast of the node as an iterator\\n        \\\"\\\"\\\"\\n        return self.filter(lambda _: True)\\n\\n    # pylint: disable=R0913\\n    def fields(\\n        self,\\n        flat: bool = True,\\n        nodes_only: bool = True,\\n        obfuscated: bool = False,\\n        nones: bool = False,\\n        named: bool = False,\\n    ) -> Iterator:\\n        \\\"\\\"\\\"\\n        Returns an iterator over fields of a node with particular filters\\n\\n        Args:\\n            flat: return a flattened iterator (if children are iterable)\\n            nodes_only: do not yield children that are not Nodes (trumped by `obfuscated`)\\n            obfuscated: yield fields that have leading underscores\\n                (typically accessed via a property)\\n            nones: yield values that are None\\n                (optional fields without a value); trumped by `nodes_only`\\n            named: yield pairs `(field name: str, field value)`\\n        Returns:\\n            Iterator: returns all children of a node given filters\\n                and optional flattening (by default Iterator[Node])\\n        \\\"\\\"\\\"\\n\\n        def make_child_generator():\\n            \\\"\\\"\\\"\\n            Makes a generator enclosing self to return\\n            not obfuscated fields (fields without starting `_`)\\n            \\\"\\\"\\\"\\n            for self_field in fields(self):\\n                if (\\n                    not self_field.name.startswith(\\\"_\\\") if not obfuscated else True\\n                ) and (self_field.name in self.__dict__):\\n                    value = self.__dict__[self_field.name]\\n                    values = [value]\\n                    if flat:\\n                        values = flatten(value)\\n                    for value in values:\\n                        if named:\\n                            yield (self_field.name, value)\\n                        else:\\n                            yield value\\n\\n        # `iter`s used to satisfy mypy (`child_generator` type changes between generator, filter)\\n        child_generator = iter(make_child_generator())\\n\\n        if nodes_only:\\n            child_generator = iter(\\n                filter(\\n                    lambda child: isinstance(child, Node)\\n                    if not named\\n                    else isinstance(child[1], Node),\\n                    child_generator,\\n                ),\\n            )\\n\\n        if not nones:\\n            child_generator = iter(\\n                filter(\\n                    lambda child: (child is not None)\\n                    if not named\\n                    else (child[1] is not None),\\n                    child_generator,\\n                ),\\n            )  # pylint: disable=C0301\\n\\n        return child_generator\\n\\n    @property\\n    def children(self) -> Iterator[\\\"Node\\\"]:\\n        \\\"\\\"\\\"\\n        Returns an iterator of all nodes that are one\\n        step from the current node down including through iterables\\n        \\\"\\\"\\\"\\n        return self.fields(\\n            flat=True,\\n            nodes_only=True,\\n            obfuscated=False,\\n            nones=False,\\n            named=False,\\n        )\\n\\n    def replace(  # pylint: disable=invalid-name\\n        self: TNode,\\n        from_: Any,\\n        to: Any,\\n        compare: Optional[Callable[[Any, Any], bool]] = None,\\n        _replace: Optional[Callable[[\\\"Node\\\", Any, Any], \\\"Node\\\"]] = None,\\n    ) -> TNode:\\n        \\\"\\\"\\\"\\n        Replace a node `from_` with a node `to` in the subtree\\n        ensures that parents and children are appropriately resolved\\n        accounts for possible cycles\\n        \\\"\\\"\\\"\\n        if _replace is None:\\n            _replace = Replacer(compare)\\n        _replace(self, from_, to)\\n        return self\\n\\n    def filter(self, func: Callable[[\\\"Node\\\"], bool]) -> Iterator[\\\"Node\\\"]:\\n        \\\"\\\"\\\"\\n        Find all nodes that `func` returns `True` for\\n        \\\"\\\"\\\"\\n        if func(self):\\n            yield self\\n\\n        for node in chain(*[child.filter(func) for child in self.children]):\\n            yield node\\n\\n    def find_all(self, node_type: Type[TNode]) -> Iterator[TNode]:\\n        \\\"\\\"\\\"\\n        Find all nodes of a particular type in the node's sub-ast\\n        \\\"\\\"\\\"\\n        return self.filter(lambda n: isinstance(n, node_type))  # type: ignore\\n\\n    def apply(self, func: Callable[[\\\"Node\\\"], None]):\\n        \\\"\\\"\\\"\\n        Traverse ast and apply func to each Node\\n        \\\"\\\"\\\"\\n        func(self)\\n        for child in self.children:\\n            child.apply(func)\\n\\n    def compare(\\n        self,\\n        other: \\\"Node\\\",\\n    ) -> bool:\\n        \\\"\\\"\\\"\\n        Compare two ASTs for deep equality\\n        \\\"\\\"\\\"\\n        if type(self) != type(other):  # pylint: disable=unidiomatic-typecheck\\n            return False\\n        if id(self) == id(other):\\n            return True\\n        return hash(self) == hash(other)\\n\\n    def diff(self, other: \\\"Node\\\") -> List[Tuple[\\\"Node\\\", \\\"Node\\\"]]:\\n        \\\"\\\"\\\"\\n        Compare two ASTs for differences and return the pairs of differences\\n        \\\"\\\"\\\"\\n\\n        def _diff(self, other: \\\"Node\\\"):\\n            if self != other:\\n                diffs.append((self, other))\\n            else:\\n                for child, other_child in zip_longest(self.children, other.children):\\n                    _diff(child, other_child)\\n\\n        diffs: List[Tuple[\\\"Node\\\", \\\"Node\\\"]] = []\\n        _diff(self, other)\\n        return diffs\\n\\n    def similarity_score(self, other: \\\"Node\\\") -> float:\\n        \\\"\\\"\\\"\\n        Determine how similar two nodes are with a float score\\n        \\\"\\\"\\\"\\n        self_nodes = list(self.flatten())\\n        other_nodes = list(other.flatten())\\n        intersection = [\\n            self_node for self_node in self_nodes if self_node in other_nodes\\n        ]\\n        union = (\\n            [self_node for self_node in self_nodes if self_node not in intersection]\\n            + [\\n                other_node\\n                for other_node in other_nodes\\n                if other_node not in intersection\\n            ]\\n            + intersection\\n        )\\n        return len(intersection) / len(union)\\n\\n    def __eq__(self, other) -> bool:\\n        \\\"\\\"\\\"\\n        Compares two nodes for \\\"top level\\\" equality.\\n\\n        Checks for type equality and primitive field types for full equality.\\n        Compares all others for type equality only. No recursing.\\n        Note: Does not check (sub)AST. See `Node.compare` for comparing (sub)ASTs.\\n        \\\"\\\"\\\"\\n        return type(self) == type(other) and all(  # pylint: disable=C0123\\n            s == o\\n            if type(s) in PRIMITIVES  # pylint: disable=C0123\\n            else type(s) == type(o)  # pylint: disable=C0123\\n            for s, o in zip(\\n                (self.fields(False, False, False, True)),\\n                (other.fields(False, False, False, True)),\\n            )\\n        )\\n\\n    def __hash__(self) -> int:\\n        \\\"\\\"\\\"\\n        Hash a node\\n        \\\"\\\"\\\"\\n        return hash(\\n            tuple(\\n                chain(\\n                    (type(self),),\\n                    self.fields(\\n                        flat=True,\\n                        nodes_only=False,\\n                        obfuscated=False,\\n                        nones=True,\\n                        named=False,\\n                    ),\\n                ),\\n            ),\\n        )\\n\\n    @abstractmethod\\n    def __str__(self) -> str:\\n        \\\"\\\"\\\"\\n        Get the string of a node\\n        \\\"\\\"\\\"\";\n",
       "                var nbb_formatted_code = \"import re\\n\\n# pylint: disable=R0401,C0302\\nfrom abc import ABC, abstractmethod\\nfrom copy import deepcopy\\nfrom dataclasses import dataclass, field, fields\\nfrom enum import Enum\\nfrom itertools import chain, zip_longest\\nfrom typing import (\\n    TYPE_CHECKING,\\n    Any,\\n    Callable,\\n    Generic,\\n    Iterator,\\n    List,\\n    Optional,\\n    Set,\\n    Tuple,\\n    Type,\\n    TypeVar,\\n    Union,\\n)\\n\\nfrom sqlmodel import Session\\n\\nfrom dj.models.database import Database\\nfrom dj.models.node import NodeRevision as DJNode\\nfrom dj.models.node import NodeType as DJNodeType\\nfrom dj.sql.functions import function_registry\\nfrom dj.sql.parsing.backends.exceptions import DJParseException\\nfrom dj.typing import ColumnType, ColumnTypeError\\nfrom datetime import timedelta\\n\\nif TYPE_CHECKING:\\n    from dj.construction.build_planning import BuildPlan  # type:ignore\\n\\nPRIMITIVES = {int, float, str, bool, type(None)}\\n\\n\\ndef flatten(maybe_iterables: Any) -> Iterator:\\n    \\\"\\\"\\\"\\n    Flattens `maybe_iterables` by descending into items that are Iterable\\n    \\\"\\\"\\\"\\n\\n    if not isinstance(maybe_iterables, (list, tuple, set, Iterator)):\\n        return iter([maybe_iterables])\\n    return chain.from_iterable(\\n        (flatten(maybe_iterable) for maybe_iterable in maybe_iterables)\\n    )\\n\\n\\ndef _raw_clean_hash(obj) -> str:\\n    \\\"\\\"\\\"\\n    Used to generate clean and unique replacement\\n     hash strings for Raw\\n\\n    >>> _raw_clean_hash(-2)\\n    'N2'\\n\\n    >>> _raw_clean_hash(1)\\n    '1'\\n    \\\"\\\"\\\"\\n    dirty = hash(obj)\\n    if dirty < 0:\\n        return f\\\"N{abs(dirty)}\\\"\\n    return str(dirty)\\n\\n\\nclass Replacer:  # pylint: disable=too-few-public-methods\\n    \\\"\\\"\\\"\\n    Replacer class keeps track of seen nodes\\n    and does the compare and replace calls\\n    while recursively calling `Node.replace`\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, compare: Optional[Callable[[Any, Any], bool]] = None):\\n        self._compare: Callable[[Any, Any], bool] = compare or (\\n            lambda a, b: a.compare(b) if isinstance(a, Node) else a == b\\n        )\\n\\n        self.seen: Set[\\n            int\\n        ] = (\\n            set()\\n        )  # to avoid infinite recursion from cycles ex. column->table->column...\\n\\n    def __call__(  # pylint: disable=too-many-branches,invalid-name\\n        self,\\n        self_node: \\\"Node\\\",\\n        from_: Any,\\n        to: Any,\\n    ):\\n        if id(self_node) in self.seen:\\n            return\\n        self.seen.add(id(self_node))\\n        for name, child in self_node.fields(\\n            flat=False,\\n            nodes_only=False,\\n            obfuscated=True,\\n            nones=False,\\n            named=True,\\n        ):\\n            iterable = False\\n            for iterable_type in (list, tuple, set):\\n                if isinstance(child, iterable_type):\\n                    iterable = True\\n                    new = []\\n                    for element in child:\\n                        if not self._compare(\\n                            element,\\n                            from_,\\n                        ):  # if the node is not a match, keep the old\\n                            new.append(element)\\n                        else:\\n                            new.append(to)\\n                        # recurse to other nodes in the iterable\\n                        if isinstance(element, Node):  # pragma: no cover\\n                            element.replace(from_, to, _replace=self)\\n                    new = iterable_type(new)  # type: ignore\\n                    setattr(self_node, name, new)\\n            if not iterable:\\n                if isinstance(child, Node):\\n                    if self._compare(child, from_):\\n                        setattr(self_node, name, to)\\n                else:\\n                    if self._compare(child, from_):\\n                        setattr(self_node, name, to)\\n            if isinstance(child, Node):\\n                child.replace(from_, to, _replace=self)\\n\\n\\nclass DJEnum(Enum):\\n    \\\"\\\"\\\"\\n    A DJ AST enum\\n    \\\"\\\"\\\"\\n\\n    def __repr__(self) -> str:\\n        return str(self)\\n\\n\\n# typevar used for node methods that return self\\n# so the typesystem can correlate the self type with the return type\\nTNode = TypeVar(\\\"TNode\\\", bound=\\\"Node\\\")  # pylint: disable=C0103\\n\\n\\nclass Node(ABC):\\n    \\\"\\\"\\\"Base class for all DJ AST nodes.\\n\\n    DJ nodes are python dataclasses with the following patterns:\\n        - Attributes are either\\n            - PRIMITIVES (int, float, str, bool, None)\\n            - iterable from (list, tuple, set)\\n            - Enum\\n            - descendant of `Node`\\n        - Attributes starting with '_' are \\\"obfuscated\\\" and are not included in `children`\\n\\n    \\\"\\\"\\\"\\n\\n    parent: Optional[\\\"Node\\\"] = None\\n    parent_key: Optional[str] = None\\n    validate_strict: Optional[bool] = True  # how to validate; `None` is no validation\\n    __instantiated = False\\n\\n    def __post_init__(self):\\n        self.add_self_as_parent()\\n        self.__instantiated = True\\n\\n    def validate(self):\\n        \\\"\\\"\\\"\\n        Validate a Node\\n        \\\"\\\"\\\"\\n\\n    def clear_parent(self: TNode) -> TNode:\\n        \\\"\\\"\\\"\\n        Remove parent from the node\\n        \\\"\\\"\\\"\\n        self.parent = None\\n        return self\\n\\n    def set_parent(self: TNode, parent: \\\"Node\\\", parent_key: str) -> TNode:\\n        \\\"\\\"\\\"\\n        Add parent to the node\\n        \\\"\\\"\\\"\\n        self.parent = parent\\n        self.parent_key = parent_key\\n        return self\\n\\n    def add_self_as_parent(self: TNode) -> TNode:\\n        \\\"\\\"\\\"\\n        Adds self as a parent to all children\\n        \\\"\\\"\\\"\\n        for name, child in self.fields(\\n            flat=True,\\n            nodes_only=True,\\n            obfuscated=False,\\n            nones=False,\\n            named=True,\\n        ):\\n            child.set_parent(self, name)\\n        return self\\n\\n    def __setattr__(self, key: str, value: Any):\\n        \\\"\\\"\\\"\\n        Facilitates setting children using `.` syntax ensuring parent is attributed\\n        \\\"\\\"\\\"\\n        if key == \\\"parent\\\":\\n            object.__setattr__(self, key, value)\\n            return\\n\\n        object.__setattr__(self, key, value)\\n        for child in flatten(value):\\n            if isinstance(child, Node) and not key.startswith(\\\"_\\\"):\\n                child.set_parent(self, key)\\n        # if node is not being instantiated for the first time let's validate\\n        if self.__instantiated:\\n            self.validate()\\n\\n    def copy(self: TNode) -> TNode:\\n        \\\"\\\"\\\"\\n        Create a deep copy of the `self`\\n        \\\"\\\"\\\"\\n        return deepcopy(self)\\n\\n    def get_nearest_parent_of_type(\\n        self: \\\"Node\\\",\\n        node_type: Type[TNode],\\n    ) -> Optional[TNode]:\\n        \\\"\\\"\\\"\\n        Traverse up the tree until you find a node of `node_type` or hit the root\\n        \\\"\\\"\\\"\\n        if isinstance(self.parent, node_type):\\n            return self.parent\\n        if self.parent is None:\\n            return None\\n        return self.parent.get_nearest_parent_of_type(node_type)\\n\\n    def flatten(self) -> Iterator[\\\"Node\\\"]:\\n        \\\"\\\"\\\"\\n        Flatten the sub-ast of the node as an iterator\\n        \\\"\\\"\\\"\\n        return self.filter(lambda _: True)\\n\\n    # pylint: disable=R0913\\n    def fields(\\n        self,\\n        flat: bool = True,\\n        nodes_only: bool = True,\\n        obfuscated: bool = False,\\n        nones: bool = False,\\n        named: bool = False,\\n    ) -> Iterator:\\n        \\\"\\\"\\\"\\n        Returns an iterator over fields of a node with particular filters\\n\\n        Args:\\n            flat: return a flattened iterator (if children are iterable)\\n            nodes_only: do not yield children that are not Nodes (trumped by `obfuscated`)\\n            obfuscated: yield fields that have leading underscores\\n                (typically accessed via a property)\\n            nones: yield values that are None\\n                (optional fields without a value); trumped by `nodes_only`\\n            named: yield pairs `(field name: str, field value)`\\n        Returns:\\n            Iterator: returns all children of a node given filters\\n                and optional flattening (by default Iterator[Node])\\n        \\\"\\\"\\\"\\n\\n        def make_child_generator():\\n            \\\"\\\"\\\"\\n            Makes a generator enclosing self to return\\n            not obfuscated fields (fields without starting `_`)\\n            \\\"\\\"\\\"\\n            for self_field in fields(self):\\n                if (\\n                    not self_field.name.startswith(\\\"_\\\") if not obfuscated else True\\n                ) and (self_field.name in self.__dict__):\\n                    value = self.__dict__[self_field.name]\\n                    values = [value]\\n                    if flat:\\n                        values = flatten(value)\\n                    for value in values:\\n                        if named:\\n                            yield (self_field.name, value)\\n                        else:\\n                            yield value\\n\\n        # `iter`s used to satisfy mypy (`child_generator` type changes between generator, filter)\\n        child_generator = iter(make_child_generator())\\n\\n        if nodes_only:\\n            child_generator = iter(\\n                filter(\\n                    lambda child: isinstance(child, Node)\\n                    if not named\\n                    else isinstance(child[1], Node),\\n                    child_generator,\\n                ),\\n            )\\n\\n        if not nones:\\n            child_generator = iter(\\n                filter(\\n                    lambda child: (child is not None)\\n                    if not named\\n                    else (child[1] is not None),\\n                    child_generator,\\n                ),\\n            )  # pylint: disable=C0301\\n\\n        return child_generator\\n\\n    @property\\n    def children(self) -> Iterator[\\\"Node\\\"]:\\n        \\\"\\\"\\\"\\n        Returns an iterator of all nodes that are one\\n        step from the current node down including through iterables\\n        \\\"\\\"\\\"\\n        return self.fields(\\n            flat=True,\\n            nodes_only=True,\\n            obfuscated=False,\\n            nones=False,\\n            named=False,\\n        )\\n\\n    def replace(  # pylint: disable=invalid-name\\n        self: TNode,\\n        from_: Any,\\n        to: Any,\\n        compare: Optional[Callable[[Any, Any], bool]] = None,\\n        _replace: Optional[Callable[[\\\"Node\\\", Any, Any], \\\"Node\\\"]] = None,\\n    ) -> TNode:\\n        \\\"\\\"\\\"\\n        Replace a node `from_` with a node `to` in the subtree\\n        ensures that parents and children are appropriately resolved\\n        accounts for possible cycles\\n        \\\"\\\"\\\"\\n        if _replace is None:\\n            _replace = Replacer(compare)\\n        _replace(self, from_, to)\\n        return self\\n\\n    def filter(self, func: Callable[[\\\"Node\\\"], bool]) -> Iterator[\\\"Node\\\"]:\\n        \\\"\\\"\\\"\\n        Find all nodes that `func` returns `True` for\\n        \\\"\\\"\\\"\\n        if func(self):\\n            yield self\\n\\n        for node in chain(*[child.filter(func) for child in self.children]):\\n            yield node\\n\\n    def find_all(self, node_type: Type[TNode]) -> Iterator[TNode]:\\n        \\\"\\\"\\\"\\n        Find all nodes of a particular type in the node's sub-ast\\n        \\\"\\\"\\\"\\n        return self.filter(lambda n: isinstance(n, node_type))  # type: ignore\\n\\n    def apply(self, func: Callable[[\\\"Node\\\"], None]):\\n        \\\"\\\"\\\"\\n        Traverse ast and apply func to each Node\\n        \\\"\\\"\\\"\\n        func(self)\\n        for child in self.children:\\n            child.apply(func)\\n\\n    def compare(\\n        self,\\n        other: \\\"Node\\\",\\n    ) -> bool:\\n        \\\"\\\"\\\"\\n        Compare two ASTs for deep equality\\n        \\\"\\\"\\\"\\n        if type(self) != type(other):  # pylint: disable=unidiomatic-typecheck\\n            return False\\n        if id(self) == id(other):\\n            return True\\n        return hash(self) == hash(other)\\n\\n    def diff(self, other: \\\"Node\\\") -> List[Tuple[\\\"Node\\\", \\\"Node\\\"]]:\\n        \\\"\\\"\\\"\\n        Compare two ASTs for differences and return the pairs of differences\\n        \\\"\\\"\\\"\\n\\n        def _diff(self, other: \\\"Node\\\"):\\n            if self != other:\\n                diffs.append((self, other))\\n            else:\\n                for child, other_child in zip_longest(self.children, other.children):\\n                    _diff(child, other_child)\\n\\n        diffs: List[Tuple[\\\"Node\\\", \\\"Node\\\"]] = []\\n        _diff(self, other)\\n        return diffs\\n\\n    def similarity_score(self, other: \\\"Node\\\") -> float:\\n        \\\"\\\"\\\"\\n        Determine how similar two nodes are with a float score\\n        \\\"\\\"\\\"\\n        self_nodes = list(self.flatten())\\n        other_nodes = list(other.flatten())\\n        intersection = [\\n            self_node for self_node in self_nodes if self_node in other_nodes\\n        ]\\n        union = (\\n            [self_node for self_node in self_nodes if self_node not in intersection]\\n            + [\\n                other_node\\n                for other_node in other_nodes\\n                if other_node not in intersection\\n            ]\\n            + intersection\\n        )\\n        return len(intersection) / len(union)\\n\\n    def __eq__(self, other) -> bool:\\n        \\\"\\\"\\\"\\n        Compares two nodes for \\\"top level\\\" equality.\\n\\n        Checks for type equality and primitive field types for full equality.\\n        Compares all others for type equality only. No recursing.\\n        Note: Does not check (sub)AST. See `Node.compare` for comparing (sub)ASTs.\\n        \\\"\\\"\\\"\\n        return type(self) == type(other) and all(  # pylint: disable=C0123\\n            s == o\\n            if type(s) in PRIMITIVES  # pylint: disable=C0123\\n            else type(s) == type(o)  # pylint: disable=C0123\\n            for s, o in zip(\\n                (self.fields(False, False, False, True)),\\n                (other.fields(False, False, False, True)),\\n            )\\n        )\\n\\n    def __hash__(self) -> int:\\n        \\\"\\\"\\\"\\n        Hash a node\\n        \\\"\\\"\\\"\\n        return hash(\\n            tuple(\\n                chain(\\n                    (type(self),),\\n                    self.fields(\\n                        flat=True,\\n                        nodes_only=False,\\n                        obfuscated=False,\\n                        nones=True,\\n                        named=False,\\n                    ),\\n                ),\\n            ),\\n        )\\n\\n    @abstractmethod\\n    def __str__(self) -> str:\\n        \\\"\\\"\\\"\\n        Get the string of a node\\n        \\\"\\\"\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# pylint: disable=R0401,C0302\n",
    "from abc import ABC, abstractmethod\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass, field, fields\n",
    "from enum import Enum\n",
    "from itertools import chain, zip_longest\n",
    "from typing import (\n",
    "    TYPE_CHECKING,\n",
    "    Any,\n",
    "    Callable,\n",
    "    Generic,\n",
    "    Iterator,\n",
    "    List,\n",
    "    Optional,\n",
    "    Set,\n",
    "    Tuple,\n",
    "    Type,\n",
    "    TypeVar,\n",
    "    Union,\n",
    ")\n",
    "\n",
    "from sqlmodel import Session\n",
    "\n",
    "from dj.models.database import Database\n",
    "from dj.models.node import NodeRevision as DJNode\n",
    "from dj.models.node import NodeType as DJNodeType\n",
    "from dj.sql.functions import function_registry\n",
    "from dj.sql.parsing.backends.exceptions import DJParseException\n",
    "from dj.typing import ColumnType, ColumnTypeError\n",
    "from datetime import timedelta\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from dj.construction.build_planning import BuildPlan  # type:ignore\n",
    "\n",
    "PRIMITIVES = {int, float, str, bool, type(None)}\n",
    "\n",
    "\n",
    "def flatten(maybe_iterables: Any) -> Iterator:\n",
    "    \"\"\"\n",
    "    Flattens `maybe_iterables` by descending into items that are Iterable\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(maybe_iterables, (list, tuple, set, Iterator)):\n",
    "        return iter([maybe_iterables])\n",
    "    return chain.from_iterable(\n",
    "        (flatten(maybe_iterable) for maybe_iterable in maybe_iterables)\n",
    "    )\n",
    "\n",
    "\n",
    "def _raw_clean_hash(obj) -> str:\n",
    "    \"\"\"\n",
    "    Used to generate clean and unique replacement\n",
    "     hash strings for Raw\n",
    "\n",
    "    >>> _raw_clean_hash(-2)\n",
    "    'N2'\n",
    "\n",
    "    >>> _raw_clean_hash(1)\n",
    "    '1'\n",
    "    \"\"\"\n",
    "    dirty = hash(obj)\n",
    "    if dirty < 0:\n",
    "        return f\"N{abs(dirty)}\"\n",
    "    return str(dirty)\n",
    "\n",
    "\n",
    "class Replacer:  # pylint: disable=too-few-public-methods\n",
    "    \"\"\"\n",
    "    Replacer class keeps track of seen nodes\n",
    "    and does the compare and replace calls\n",
    "    while recursively calling `Node.replace`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, compare: Optional[Callable[[Any, Any], bool]] = None):\n",
    "        self._compare: Callable[[Any, Any], bool] = compare or (\n",
    "            lambda a, b: a.compare(b) if isinstance(a, Node) else a == b\n",
    "        )\n",
    "\n",
    "        self.seen: Set[\n",
    "            int\n",
    "        ] = (\n",
    "            set()\n",
    "        )  # to avoid infinite recursion from cycles ex. column->table->column...\n",
    "\n",
    "    def __call__(  # pylint: disable=too-many-branches,invalid-name\n",
    "        self,\n",
    "        self_node: \"Node\",\n",
    "        from_: Any,\n",
    "        to: Any,\n",
    "    ):\n",
    "        if id(self_node) in self.seen:\n",
    "            return\n",
    "        self.seen.add(id(self_node))\n",
    "        for name, child in self_node.fields(\n",
    "            flat=False,\n",
    "            nodes_only=False,\n",
    "            obfuscated=True,\n",
    "            nones=False,\n",
    "            named=True,\n",
    "        ):\n",
    "            iterable = False\n",
    "            for iterable_type in (list, tuple, set):\n",
    "                if isinstance(child, iterable_type):\n",
    "                    iterable = True\n",
    "                    new = []\n",
    "                    for element in child:\n",
    "                        if not self._compare(\n",
    "                            element,\n",
    "                            from_,\n",
    "                        ):  # if the node is not a match, keep the old\n",
    "                            new.append(element)\n",
    "                        else:\n",
    "                            new.append(to)\n",
    "                        # recurse to other nodes in the iterable\n",
    "                        if isinstance(element, Node):  # pragma: no cover\n",
    "                            element.replace(from_, to, _replace=self)\n",
    "                    new = iterable_type(new)  # type: ignore\n",
    "                    setattr(self_node, name, new)\n",
    "            if not iterable:\n",
    "                if isinstance(child, Node):\n",
    "                    if self._compare(child, from_):\n",
    "                        setattr(self_node, name, to)\n",
    "                else:\n",
    "                    if self._compare(child, from_):\n",
    "                        setattr(self_node, name, to)\n",
    "            if isinstance(child, Node):\n",
    "                child.replace(from_, to, _replace=self)\n",
    "\n",
    "\n",
    "class DJEnum(Enum):\n",
    "    \"\"\"\n",
    "    A DJ AST enum\n",
    "    \"\"\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self)\n",
    "\n",
    "\n",
    "# typevar used for node methods that return self\n",
    "# so the typesystem can correlate the self type with the return type\n",
    "TNode = TypeVar(\"TNode\", bound=\"Node\")  # pylint: disable=C0103\n",
    "\n",
    "\n",
    "class Node(ABC):\n",
    "    \"\"\"Base class for all DJ AST nodes.\n",
    "\n",
    "    DJ nodes are python dataclasses with the following patterns:\n",
    "        - Attributes are either\n",
    "            - PRIMITIVES (int, float, str, bool, None)\n",
    "            - iterable from (list, tuple, set)\n",
    "            - Enum\n",
    "            - descendant of `Node`\n",
    "        - Attributes starting with '_' are \"obfuscated\" and are not included in `children`\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    parent: Optional[\"Node\"] = None\n",
    "    parent_key: Optional[str] = None\n",
    "    validate_strict: Optional[bool] = True  # how to validate; `None` is no validation\n",
    "    __instantiated = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.add_self_as_parent()\n",
    "        self.__instantiated = True\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"\n",
    "        Validate a Node\n",
    "        \"\"\"\n",
    "\n",
    "    def clear_parent(self: TNode) -> TNode:\n",
    "        \"\"\"\n",
    "        Remove parent from the node\n",
    "        \"\"\"\n",
    "        self.parent = None\n",
    "        return self\n",
    "\n",
    "    def set_parent(self: TNode, parent: \"Node\", parent_key: str) -> TNode:\n",
    "        \"\"\"\n",
    "        Add parent to the node\n",
    "        \"\"\"\n",
    "        self.parent = parent\n",
    "        self.parent_key = parent_key\n",
    "        return self\n",
    "\n",
    "    def add_self_as_parent(self: TNode) -> TNode:\n",
    "        \"\"\"\n",
    "        Adds self as a parent to all children\n",
    "        \"\"\"\n",
    "        for name, child in self.fields(\n",
    "            flat=True,\n",
    "            nodes_only=True,\n",
    "            obfuscated=False,\n",
    "            nones=False,\n",
    "            named=True,\n",
    "        ):\n",
    "            child.set_parent(self, name)\n",
    "        return self\n",
    "\n",
    "    def __setattr__(self, key: str, value: Any):\n",
    "        \"\"\"\n",
    "        Facilitates setting children using `.` syntax ensuring parent is attributed\n",
    "        \"\"\"\n",
    "        if key == \"parent\":\n",
    "            object.__setattr__(self, key, value)\n",
    "            return\n",
    "\n",
    "        object.__setattr__(self, key, value)\n",
    "        for child in flatten(value):\n",
    "            if isinstance(child, Node) and not key.startswith(\"_\"):\n",
    "                child.set_parent(self, key)\n",
    "        # if node is not being instantiated for the first time let's validate\n",
    "        if self.__instantiated:\n",
    "            self.validate()\n",
    "\n",
    "    def copy(self: TNode) -> TNode:\n",
    "        \"\"\"\n",
    "        Create a deep copy of the `self`\n",
    "        \"\"\"\n",
    "        return deepcopy(self)\n",
    "\n",
    "    def get_nearest_parent_of_type(\n",
    "        self: \"Node\",\n",
    "        node_type: Type[TNode],\n",
    "    ) -> Optional[TNode]:\n",
    "        \"\"\"\n",
    "        Traverse up the tree until you find a node of `node_type` or hit the root\n",
    "        \"\"\"\n",
    "        if isinstance(self.parent, node_type):\n",
    "            return self.parent\n",
    "        if self.parent is None:\n",
    "            return None\n",
    "        return self.parent.get_nearest_parent_of_type(node_type)\n",
    "\n",
    "    def flatten(self) -> Iterator[\"Node\"]:\n",
    "        \"\"\"\n",
    "        Flatten the sub-ast of the node as an iterator\n",
    "        \"\"\"\n",
    "        return self.filter(lambda _: True)\n",
    "\n",
    "    # pylint: disable=R0913\n",
    "    def fields(\n",
    "        self,\n",
    "        flat: bool = True,\n",
    "        nodes_only: bool = True,\n",
    "        obfuscated: bool = False,\n",
    "        nones: bool = False,\n",
    "        named: bool = False,\n",
    "    ) -> Iterator:\n",
    "        \"\"\"\n",
    "        Returns an iterator over fields of a node with particular filters\n",
    "\n",
    "        Args:\n",
    "            flat: return a flattened iterator (if children are iterable)\n",
    "            nodes_only: do not yield children that are not Nodes (trumped by `obfuscated`)\n",
    "            obfuscated: yield fields that have leading underscores\n",
    "                (typically accessed via a property)\n",
    "            nones: yield values that are None\n",
    "                (optional fields without a value); trumped by `nodes_only`\n",
    "            named: yield pairs `(field name: str, field value)`\n",
    "        Returns:\n",
    "            Iterator: returns all children of a node given filters\n",
    "                and optional flattening (by default Iterator[Node])\n",
    "        \"\"\"\n",
    "\n",
    "        def make_child_generator():\n",
    "            \"\"\"\n",
    "            Makes a generator enclosing self to return\n",
    "            not obfuscated fields (fields without starting `_`)\n",
    "            \"\"\"\n",
    "            for self_field in fields(self):\n",
    "                if (\n",
    "                    not self_field.name.startswith(\"_\") if not obfuscated else True\n",
    "                ) and (self_field.name in self.__dict__):\n",
    "                    value = self.__dict__[self_field.name]\n",
    "                    values = [value]\n",
    "                    if flat:\n",
    "                        values = flatten(value)\n",
    "                    for value in values:\n",
    "                        if named:\n",
    "                            yield (self_field.name, value)\n",
    "                        else:\n",
    "                            yield value\n",
    "\n",
    "        # `iter`s used to satisfy mypy (`child_generator` type changes between generator, filter)\n",
    "        child_generator = iter(make_child_generator())\n",
    "\n",
    "        if nodes_only:\n",
    "            child_generator = iter(\n",
    "                filter(\n",
    "                    lambda child: isinstance(child, Node)\n",
    "                    if not named\n",
    "                    else isinstance(child[1], Node),\n",
    "                    child_generator,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        if not nones:\n",
    "            child_generator = iter(\n",
    "                filter(\n",
    "                    lambda child: (child is not None)\n",
    "                    if not named\n",
    "                    else (child[1] is not None),\n",
    "                    child_generator,\n",
    "                ),\n",
    "            )  # pylint: disable=C0301\n",
    "\n",
    "        return child_generator\n",
    "\n",
    "    @property\n",
    "    def children(self) -> Iterator[\"Node\"]:\n",
    "        \"\"\"\n",
    "        Returns an iterator of all nodes that are one\n",
    "        step from the current node down including through iterables\n",
    "        \"\"\"\n",
    "        return self.fields(\n",
    "            flat=True,\n",
    "            nodes_only=True,\n",
    "            obfuscated=False,\n",
    "            nones=False,\n",
    "            named=False,\n",
    "        )\n",
    "\n",
    "    def replace(  # pylint: disable=invalid-name\n",
    "        self: TNode,\n",
    "        from_: Any,\n",
    "        to: Any,\n",
    "        compare: Optional[Callable[[Any, Any], bool]] = None,\n",
    "        _replace: Optional[Callable[[\"Node\", Any, Any], \"Node\"]] = None,\n",
    "    ) -> TNode:\n",
    "        \"\"\"\n",
    "        Replace a node `from_` with a node `to` in the subtree\n",
    "        ensures that parents and children are appropriately resolved\n",
    "        accounts for possible cycles\n",
    "        \"\"\"\n",
    "        if _replace is None:\n",
    "            _replace = Replacer(compare)\n",
    "        _replace(self, from_, to)\n",
    "        return self\n",
    "\n",
    "    def filter(self, func: Callable[[\"Node\"], bool]) -> Iterator[\"Node\"]:\n",
    "        \"\"\"\n",
    "        Find all nodes that `func` returns `True` for\n",
    "        \"\"\"\n",
    "        if func(self):\n",
    "            yield self\n",
    "\n",
    "        for node in chain(*[child.filter(func) for child in self.children]):\n",
    "            yield node\n",
    "\n",
    "    def find_all(self, node_type: Type[TNode]) -> Iterator[TNode]:\n",
    "        \"\"\"\n",
    "        Find all nodes of a particular type in the node's sub-ast\n",
    "        \"\"\"\n",
    "        return self.filter(lambda n: isinstance(n, node_type))  # type: ignore\n",
    "\n",
    "    def apply(self, func: Callable[[\"Node\"], None]):\n",
    "        \"\"\"\n",
    "        Traverse ast and apply func to each Node\n",
    "        \"\"\"\n",
    "        func(self)\n",
    "        for child in self.children:\n",
    "            child.apply(func)\n",
    "\n",
    "    def compare(\n",
    "        self,\n",
    "        other: \"Node\",\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        Compare two ASTs for deep equality\n",
    "        \"\"\"\n",
    "        if type(self) != type(other):  # pylint: disable=unidiomatic-typecheck\n",
    "            return False\n",
    "        if id(self) == id(other):\n",
    "            return True\n",
    "        return hash(self) == hash(other)\n",
    "\n",
    "    def diff(self, other: \"Node\") -> List[Tuple[\"Node\", \"Node\"]]:\n",
    "        \"\"\"\n",
    "        Compare two ASTs for differences and return the pairs of differences\n",
    "        \"\"\"\n",
    "\n",
    "        def _diff(self, other: \"Node\"):\n",
    "            if self != other:\n",
    "                diffs.append((self, other))\n",
    "            else:\n",
    "                for child, other_child in zip_longest(self.children, other.children):\n",
    "                    _diff(child, other_child)\n",
    "\n",
    "        diffs: List[Tuple[\"Node\", \"Node\"]] = []\n",
    "        _diff(self, other)\n",
    "        return diffs\n",
    "\n",
    "    def similarity_score(self, other: \"Node\") -> float:\n",
    "        \"\"\"\n",
    "        Determine how similar two nodes are with a float score\n",
    "        \"\"\"\n",
    "        self_nodes = list(self.flatten())\n",
    "        other_nodes = list(other.flatten())\n",
    "        intersection = [\n",
    "            self_node for self_node in self_nodes if self_node in other_nodes\n",
    "        ]\n",
    "        union = (\n",
    "            [self_node for self_node in self_nodes if self_node not in intersection]\n",
    "            + [\n",
    "                other_node\n",
    "                for other_node in other_nodes\n",
    "                if other_node not in intersection\n",
    "            ]\n",
    "            + intersection\n",
    "        )\n",
    "        return len(intersection) / len(union)\n",
    "\n",
    "    def __eq__(self, other) -> bool:\n",
    "        \"\"\"\n",
    "        Compares two nodes for \"top level\" equality.\n",
    "\n",
    "        Checks for type equality and primitive field types for full equality.\n",
    "        Compares all others for type equality only. No recursing.\n",
    "        Note: Does not check (sub)AST. See `Node.compare` for comparing (sub)ASTs.\n",
    "        \"\"\"\n",
    "        return type(self) == type(other) and all(  # pylint: disable=C0123\n",
    "            s == o\n",
    "            if type(s) in PRIMITIVES  # pylint: disable=C0123\n",
    "            else type(s) == type(o)  # pylint: disable=C0123\n",
    "            for s, o in zip(\n",
    "                (self.fields(False, False, False, True)),\n",
    "                (other.fields(False, False, False, True)),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        \"\"\"\n",
    "        Hash a node\n",
    "        \"\"\"\n",
    "        return hash(\n",
    "            tuple(\n",
    "                chain(\n",
    "                    (type(self),),\n",
    "                    self.fields(\n",
    "                        flat=True,\n",
    "                        nodes_only=False,\n",
    "                        obfuscated=False,\n",
    "                        nones=True,\n",
    "                        named=False,\n",
    "                    ),\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the string of a node\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6089f867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:object of type 'ABCMeta' has no len()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/lab_black.py\", line 206, in format_cell\n",
      "    cell_id = len(self.shell.user_ns[\"In\"]) - 1\n",
      "TypeError: object of type 'ABCMeta' has no len()\n"
     ]
    }
   ],
   "source": [
    "TExpression = TypeVar(\"TExpression\", bound=\"Expression\")  # pylint: disable=C0103\n",
    "\n",
    "\n",
    "class Expression(Node):\n",
    "    \"\"\"\n",
    "    An expression type simply for type checking\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def type(self) -> ColumnType:\n",
    "        \"\"\"\n",
    "        Return the type of the expression\n",
    "        \"\"\"\n",
    "        from dj.construction.inference import (  # pylint: disable=C0415\n",
    "            get_type_of_expression,\n",
    "        )\n",
    "\n",
    "        return get_type_of_expression(self)\n",
    "\n",
    "    def is_aggregation(self) -> bool:\n",
    "        \"\"\"\n",
    "        Determines whether an Expression is an aggregation or not\n",
    "        \"\"\"\n",
    "        return all(\n",
    "            [\n",
    "                child.is_aggregation()\n",
    "                for child in self.children\n",
    "                if isinstance(child, Expression)\n",
    "            ]\n",
    "            or [False],\n",
    "        )\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Name(Node):\n",
    "    \"\"\"\n",
    "    The string name specified in sql with quote style\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    quote_style: str = \"\"\n",
    "\n",
    "    def to_named_type(self, named_type: Type[\"Named\"]) -> \"Named\":\n",
    "        \"\"\"\n",
    "        Transform the name into a specific Named that only requires a name to create\n",
    "        \"\"\"\n",
    "        return named_type(self)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return (\n",
    "            f\"{self.quote_style}{self.name}{self.quote_style}\"  # pylint: disable=C0301\n",
    "        )\n",
    "\n",
    "\n",
    "TNamed = TypeVar(\"TNamed\", bound=\"Named\")  # pylint: disable=C0103\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Namespace(Node):\n",
    "    \"\"\"\n",
    "    Represents a sequence of names prececeding some Table or Column\n",
    "    \"\"\"\n",
    "\n",
    "    names: List[Name]\n",
    "\n",
    "    def to_named_type(self, named_type: Type[TNamed]) -> TNamed:\n",
    "        \"\"\"\n",
    "        Transform the namespace into a column\n",
    "        whose name is the last name in the namespace\n",
    "\n",
    "        if the namespace contains a single name,\n",
    "            the created column will have no namespace\n",
    "        otherwise, the remaining names for the column's namespace\n",
    "        \"\"\"\n",
    "        if not self.names:\n",
    "            raise DJParseException(\"Namespace is empty\")\n",
    "        converted = named_type(self.names.pop().clear_parent())\n",
    "        if self.names:\n",
    "            converted.add_namespace(self)\n",
    "        return converted\n",
    "\n",
    "    def pop_self(self) -> Tuple[\"Namespace\", Name]:\n",
    "        \"\"\"\n",
    "        A utility function that returns the last name\n",
    "        and the remaining namespace as a tuple\n",
    "\n",
    "        useful for parsing compound identifiers and revealing\n",
    "        the last name for another attribute\n",
    "        \"\"\"\n",
    "        last = self.names.pop().clear_parent()\n",
    "        return self, last\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \".\".join(str(name) for name in self.names)\n",
    "\n",
    "\n",
    "@dataclass(eq=False)  # type: ignore\n",
    "class Named(Expression):\n",
    "    \"\"\"\n",
    "    An Expression that has a name\n",
    "    \"\"\"\n",
    "\n",
    "    name: Name\n",
    "\n",
    "    namespace: Optional[Namespace] = None\n",
    "\n",
    "    def add_namespace(self: TNamed, namespace: Optional[Namespace]) -> TNamed:\n",
    "        \"\"\"\n",
    "        Add a namespace to the Named if one does not exist\n",
    "        \"\"\"\n",
    "        if self.namespace is None:\n",
    "            self.namespace = namespace\n",
    "        return self\n",
    "\n",
    "    def identifier(self, quotes: bool = True) -> str:\n",
    "        return \".\".join(\n",
    "            (\n",
    "                *(str(name) if quotes else name.name for name in self.namespace),\n",
    "                str(self.name) if quotes else self.name.name,\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "@dataclass(eq=False)  # type: ignore\n",
    "class Aliasable(Expression):\n",
    "    \"\"\"\n",
    "    An Expression that has a name\n",
    "    \"\"\"\n",
    "\n",
    "    alias: Optional[Name] = None\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        if self.alias is None and isinstance(self, Named):\n",
    "            return self.name\n",
    "        return self.alias\n",
    "\n",
    "\n",
    "class Operation(Expression):\n",
    "    \"\"\"\n",
    "    A type to overarch types that operate on other expressions\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class UnaryOp(Operation):\n",
    "    \"\"\"\n",
    "    An operation that operates on a single expression\n",
    "    \"\"\"\n",
    "\n",
    "    op: str\n",
    "    expr: Expression\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.op} {(self.expr)}\"\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class BinaryOp(Operation):\n",
    "    \"\"\"\n",
    "    Represents an operation that operates on two expressions\n",
    "    \"\"\"\n",
    "\n",
    "    op: str\n",
    "    left: Expression\n",
    "    right: Expression\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.left} {self.op} {self.right}\"\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Case(Expression):\n",
    "    \"\"\"\n",
    "    A case statement of branches\n",
    "    \"\"\"\n",
    "\n",
    "    conditions: List[Expression] = field(default_factory=list)\n",
    "    else_result: Optional[Expression] = None\n",
    "    operand: Optional[Expression] = None\n",
    "    results: List[Expression] = field(default_factory=list)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        branches = \"\\n\\tWHEN \".join(\n",
    "            f\"{(cond)} THEN {(result)}\"\n",
    "            for cond, result in zip(self.conditions, self.results)\n",
    "        )\n",
    "        return f\"\"\"(CASE\n",
    "        WHEN {branches}\n",
    "        ELSE {(self.else_result)}\n",
    "    END)\"\"\"\n",
    "\n",
    "    def is_aggregation(self) -> bool:\n",
    "        return all(result.is_aggregation() for result in self.results) and (\n",
    "            self.else_result.is_aggregation() if self.else_result else True\n",
    "        )\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Over(Expression):\n",
    "    \"\"\"\n",
    "    Represents a function used in a statement\n",
    "    \"\"\"\n",
    "\n",
    "    partition_by: List[Expression] = field(default_factory=list)\n",
    "    order_by: List[\"Order\"] = field(default_factory=list)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "        self.validate()\n",
    "\n",
    "    def validate(self):\n",
    "        super().validate()\n",
    "        if not (self.partition_by or self.order_by):\n",
    "            raise DJParseException(\n",
    "                \"An OVER requires at least a PARTITION BY or ORDER BY\",\n",
    "            )\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        partition_by = (  # pragma: no cover\n",
    "            \" PARTITION BY \" + \", \".join(str(exp) for exp in self.partition_by)\n",
    "            if self.partition_by\n",
    "            else \"\"\n",
    "        )\n",
    "        order_by = (\n",
    "            \" ORDER BY \" + \", \".join(str(exp) for exp in self.order_by)\n",
    "            if self.order_by\n",
    "            else \"\"\n",
    "        )\n",
    "        consolidated_by = \"\\n\".join(\n",
    "            po_by for po_by in (partition_by, order_by) if po_by\n",
    "        )\n",
    "        return f\"OVER ({consolidated_by})\"\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Function(Named, Operation):\n",
    "    \"\"\"\n",
    "    Represents a function used in a statement\n",
    "    \"\"\"\n",
    "\n",
    "    args: List[Expression] = field(default_factory=list)\n",
    "    quantifier: str = \"\"\n",
    "    over: Optional[Over] = None\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        over = f\" {self.over}\" if self.over else \"\"\n",
    "        return f\"{self.name}({self.quantifier}{', '.join(str(arg) for arg in self.args)}){over}\"\n",
    "\n",
    "    def is_aggregation(self) -> bool:\n",
    "        return function_registry[self.name.name.upper()].is_aggregation\n",
    "\n",
    "\n",
    "@dataclass(eq=False)  # type: ignore\n",
    "class Value(Expression):\n",
    "    \"\"\"\n",
    "    Base class for all values number, string, boolean\n",
    "    \"\"\"\n",
    "\n",
    "    value: Union[str, bool, float, int, None]\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        if isinstance(self, String):\n",
    "            return f\"'{self.value}'\"\n",
    "        return str(self.value)\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Null(Value):\n",
    "    \"\"\"\n",
    "    Null value\n",
    "    \"\"\"\n",
    "\n",
    "    value = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "        self.validate()\n",
    "\n",
    "    def validate(self):\n",
    "        super().validate()\n",
    "        if self.value is not None:\n",
    "            raise DJParseException(\"NULL does not take a value.\")\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Number(Value):\n",
    "    \"\"\"\n",
    "    Number value\n",
    "    \"\"\"\n",
    "\n",
    "    value: Union[float, int]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "        self.validate()\n",
    "\n",
    "    def validate(self):\n",
    "        super().validate()\n",
    "        if type(self.value) not in (float, int):\n",
    "            try:\n",
    "                self.value = int(self.value)\n",
    "            except ValueError:\n",
    "                self.value = float(self.value)\n",
    "\n",
    "\n",
    "class String(Value):\n",
    "    \"\"\"\n",
    "    String value\n",
    "    \"\"\"\n",
    "\n",
    "    value: str\n",
    "\n",
    "\n",
    "class Boolean(Value):\n",
    "    \"\"\"\n",
    "    Boolean True/False value\n",
    "    \"\"\"\n",
    "\n",
    "    value: bool\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Interval(Value):\n",
    "    \"\"\"\n",
    "    Interval value\n",
    "    \"\"\"\n",
    "\n",
    "    value: timedelta\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Predicate(Operation):\n",
    "    \"\"\"\n",
    "    Represents a predicate\n",
    "    \"\"\"\n",
    "\n",
    "    negated: bool = False\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Between(Predicate):\n",
    "    \"\"\"\n",
    "    A between statement\n",
    "    \"\"\"\n",
    "\n",
    "    expr: Expression = field(default_factory=Expression)\n",
    "    low: Expression = field(default_factory=Expression)\n",
    "    high: Expression = field(default_factory=Expression)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        not_ = \"NOT \" if self.negated else \"\"\n",
    "        return f\"{not_}{self.expr} BETWEEN {self.low} AND {self.high}\"\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class In(Predicate):\n",
    "    \"\"\"\n",
    "    An in expression\n",
    "    \"\"\"\n",
    "\n",
    "    expr: Expression = field(default_factory=Expression)\n",
    "    source: Union[List[Expression], \"Select\"] = field(default_factory=Expression)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        not_ = \"NOT \" if self.negated else \"\"\n",
    "        source = (\n",
    "            str(self.source)\n",
    "            if isinstance(self.source, Select)\n",
    "            else \"(\" + \", \".join(str(exp) for exp in self.source) + \")\"\n",
    "        )\n",
    "        return f\"{self.expr} {not_}IN {source}\"\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Rlike(Predicate):\n",
    "    \"\"\"\n",
    "    A regular expression match statement\n",
    "    \"\"\"\n",
    "\n",
    "    expr: Expression = field(default_factory=Expression)\n",
    "    pattern: Expression = field(default_factory=Expression)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        not_ = \"NOT \" if self.negated else \"\"\n",
    "        return f\"{not_}{self.expr} RLIKE {self.pattern}\"\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Like(Predicate):\n",
    "    \"\"\"\n",
    "    A string pattern matching statement\n",
    "    \"\"\"\n",
    "\n",
    "    expr: Expression = field(default_factory=Expression)\n",
    "    quantifier: str = \"\"\n",
    "    patterns: List[Expression] = field(default_factory=list)\n",
    "    escape_char: Optional[str] = None\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        not_ = \"NOT \" if self.negated else \"\"\n",
    "        patterns = \", \".join(str(p) for p in self.patterns)\n",
    "        escape_char = f\" ESCAPE '{self.escape_char}'\" if self.escape_char else \"\"\n",
    "        return f\"{not_}{self.expr} LIKE {self.quantifier} ({patterns}){escape_char}\"\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class IsNull(Predicate):\n",
    "    \"\"\"\n",
    "    A null check statement\n",
    "    \"\"\"\n",
    "\n",
    "    expr: Expression = field(default_factory=Expression)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        not_ = \"NOT \" if self.negated else \"\"\n",
    "        return f\"{self.expr} IS {not_}NULL\"\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class IsBoolean(Predicate):\n",
    "    \"\"\"\n",
    "    A boolean check statement\n",
    "    \"\"\"\n",
    "\n",
    "    expr: Expression = field(default_factory=Expression)\n",
    "    value: str = \"UNKNOWN\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        not_ = \"NOT \" if self.negated else \"\"\n",
    "        return f\"{self.expr} IS {not_}{self.value}\"\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class IsDistinctFrom(Predicate):\n",
    "    \"\"\"\n",
    "    A distinct from check statement\n",
    "    \"\"\"\n",
    "\n",
    "    expr: Expression = field(default_factory=Expression)\n",
    "    right: Expression = field(default_factory=Expression)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        not_ = \"NOT \" if self.negated else \"\"\n",
    "        return f\"{self.expr} IS {not_}DISTINCT FROM {self.right}\"\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Case(Expression):\n",
    "    \"\"\"\n",
    "    A case statement of branches\n",
    "    \"\"\"\n",
    "\n",
    "    conditions: List[Expression] = field(default_factory=list)\n",
    "    else_result: Optional[Expression] = None\n",
    "    operand: Optional[Expression] = None\n",
    "    results: List[Expression] = field(default_factory=list)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        branches = \"\\n\\tWHEN \".join(\n",
    "            f\"{(cond)} THEN {(result)}\"\n",
    "            for cond, result in zip(self.conditions, self.results)\n",
    "        )\n",
    "        return f\"\"\"(CASE\n",
    "        WHEN {branches}\n",
    "        ELSE {(self.else_result)}\n",
    "    END)\"\"\"\n",
    "\n",
    "    def is_aggregation(self) -> bool:\n",
    "        return all(result.is_aggregation() for result in self.results) and (\n",
    "            self.else_result.is_aggregation() if self.else_result else True\n",
    "        )\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Subscript(Expression):\n",
    "    \"\"\"\n",
    "    Represents a subscript expression\n",
    "    \"\"\"\n",
    "\n",
    "    expr: Expression\n",
    "    index: Expression\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.expr}[{self.index}]\"\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Lambda(Expression):\n",
    "    \"\"\"\n",
    "    Represents a lambda expression\n",
    "    \"\"\"\n",
    "\n",
    "    identifiers: List[Named]\n",
    "    expr: Expression\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        id_str = \", \".join(str(iden) for iden in self.identifiers)\n",
    "        return f\"({id_str}) -> {self.expr}\"\n",
    "    \n",
    "@dataclass(eq=False)\n",
    "class JoinCriteria:\n",
    "    \"\"\"\n",
    "    Represents the criteria for a join relation in a FROM clause\n",
    "    \"\"\"\n",
    "\n",
    "    on: Optional[Expression] = None\n",
    "    using: Optional[List[Named]] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.validate()\n",
    "\n",
    "    def validate(self):\n",
    "        if self.on is None and self.using is None:\n",
    "            raise DJParseException(f\"Expected either an ON or USING clause at {self}.\")\n",
    "        if self.on is not None and self.using is not None:\n",
    "            raise DJParseException(\n",
    "                f\"Expected either an ON or USING clause, not both, at {self}.\"\n",
    "            )\n",
    "        if self.on is not None:\n",
    "            self.on.validate()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        if self.on:\n",
    "            return f\"ON {self.on}\"\n",
    "        else:\n",
    "            id_list = \", \".join(str(iden) for iden in self.using)\n",
    "            return f\"USING ({id_list})\"\n",
    "        \n",
    "@dataclass(eq=False)\n",
    "class Join:\n",
    "    \"\"\"\n",
    "    Represents a join relation in a FROM clause\n",
    "    \"\"\"\n",
    "\n",
    "    join_type: str\n",
    "    table: Expression\n",
    "    criteria: Optional[JoinCriteria] = None\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        parts = []\n",
    "        if self.join_type:\n",
    "            parts.append(f\"{self.join_type} \")\n",
    "        parts.append(\"JOIN \")\n",
    "        parts.append(str(self.table))\n",
    "        if self.criteria:\n",
    "            parts.append(f\" {self.criteria}\")\n",
    "        return \"\".join(parts)\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class From:\n",
    "    \"\"\"\n",
    "    Represents the FROM clause of a SELECT statement\n",
    "    \"\"\"\n",
    "\n",
    "    tables: List[Expression]\n",
    "    joins: List[Join]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.validate()\n",
    "\n",
    "    def validate(self):\n",
    "        if not self.tables:\n",
    "            raise DJParseException(\n",
    "                f\"Expected at least one table in from clause at {self}.\"\n",
    "            )\n",
    "        for table in self.tables:\n",
    "            table.validate()\n",
    "        for join in self.joins:\n",
    "            join.validate()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        parts = [\"FROM \"]\n",
    "        parts.append(str(self.tables[0]))\n",
    "        for i in range(1, len(self.tables)):\n",
    "            parts.append(\", \")\n",
    "            parts.append(str(self.tables[i]))\n",
    "        for join in self.joins:\n",
    "            parts.append(f\"\\n{join}\")\n",
    "        return \"\".join(parts)\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class FunctionTable(Aliasable, Operation):\n",
    "    \"\"\"\n",
    "    Represents a function used in a statement\n",
    "    \"\"\"\n",
    "\n",
    "    args: List[Expression] = field(default_factory=list)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.name}({', '.join(str(arg) for arg in self.args)})\"\n",
    "\n",
    "    \n",
    "@dataclass(eq=False)\n",
    "class Select(Aliasable):\n",
    "    \"\"\"\n",
    "    A single select statement type\n",
    "    \"\"\"\n",
    "\n",
    "    quantifier: str = \"\"  # Distinct, All\n",
    "    projection: List[Expression] = field(default_factory=list)\n",
    "    from_: Optional[From] = None\n",
    "    group_by: List[Expression] = field(default_factory=list)\n",
    "    having: Optional[Expression] = None\n",
    "    where: Optional[Expression] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "        self.validate()\n",
    "\n",
    "    def validate(self):\n",
    "        super().validate()\n",
    "        if not self.projection:\n",
    "            raise DJParseException(\n",
    "                f\"Expected at least a single item in projection at {self}.\"\n",
    "            )\n",
    "\n",
    "    def add_aliases_to_unnamed_columns(self) -> None:\n",
    "        \"\"\"\n",
    "        Add an alias to any unnamed columns in the projection (`col{n}`)\n",
    "        \"\"\"\n",
    "        for i, expression in enumerate(self.projection):\n",
    "            if not isinstance(expression, (Column, Alias)):\n",
    "                name = f\"col{i}\"\n",
    "                aliased = Alias(Name(name), child=expression)\n",
    "                # only replace those that are identical in memory\n",
    "                self.replace(expression, aliased, lambda a, b: id(a) == id(b))\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        subselect = not (\n",
    "            isinstance(self.parent, Query)\n",
    "            or self.parent is None\n",
    "            or self.alias is not None\n",
    "        )\n",
    "        parts = [\"SELECT \"]\n",
    "        if self.quantifier:\n",
    "            parts.append(f\"{self.quantifier} \")\n",
    "        parts.append(\",\\n\\t\".join(str(exp) for exp in self.projection))\n",
    "        if self.from_ is not None:\n",
    "            parts.extend((\"\\n\", str(self.from_), \"\\n\"))\n",
    "        if self.where is not None:\n",
    "            parts.extend((\"WHERE \", str(self.where), \"\\n\"))\n",
    "        if self.group_by:\n",
    "            parts.extend((\"GROUP BY \", \", \".join(str(exp) for exp in self.group_by)))\n",
    "        if self.having is not None:\n",
    "            parts.extend((\"HAVING \", str(self.having), \"\\n\"))\n",
    "\n",
    "        select = \" \".join(parts).strip()\n",
    "        if subselect:\n",
    "            return \"(\" + select + \")\"\n",
    "        return select\n",
    "\n",
    "\n",
    "@dataclass(eq=False)\n",
    "class Order(Node):\n",
    "    \"\"\"\n",
    "    A column wrapper for ordering\n",
    "    \"\"\"\n",
    "\n",
    "    kind: str #ORDER | SORT\n",
    "    expr: Expression\n",
    "    order: str #(ASC | DESC)? (NULLS nullOrder=(LAST | FIRST))?\n",
    "    \n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.kind} BY {self.expr} {self.order}\"\n",
    "    \n",
    "@dataclass(eq=False)\n",
    "class SetOp(Node):\n",
    "    \"\"\"\n",
    "    A column wrapper for ordering\n",
    "    \"\"\"\n",
    "    left: Union[Select, \"SetOp\"]\n",
    "    kind: str #Union, intersect, ...\n",
    "    right: Union[Select, \"SetOp\"]\n",
    "    \n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.left} {self.kind} {self.right}\"\n",
    "    \n",
    "@dataclass(eq=False)\n",
    "class Query(Expression):\n",
    "    \"\"\"\n",
    "    Overarching query type\n",
    "    \"\"\"\n",
    "\n",
    "    select: Union[Select, SetOp]\n",
    "    ctes: List[\"Select\"] = field(default_factory=list)\n",
    "    limit: Optional[Expression] = None\n",
    "    quantifier: str = \"\"\n",
    "    ordering: List[Order] = field(default_factory=list)\n",
    "    sets: List[SetOp] = field(default_factory=list)\n",
    "        \n",
    "    def _to_select(self) -> Select:\n",
    "        \"\"\"\n",
    "        Compile ctes into the select and return the select\n",
    "\n",
    "        Note: This destroys the structure of the query which cannot be undone\n",
    "        you may want to deepcopy it first\n",
    "        \"\"\"\n",
    "        for cte in self.ctes:\n",
    "            table = Table(cte.name, cte.namespace)\n",
    "            self.select.replace(table, cte)\n",
    "        return self.select\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        subquery = bool(self.parent)\n",
    "        ctes = \",\\n\".join(f\"{cte.name} AS ({cte.child})\" for cte in self.ctes)\n",
    "        with_ = \"WITH\" if ctes else \"\"\n",
    "        select = f\"({(self.select)})\" if subquery else (self.select)\n",
    "        parts = [f\"{with_}\\n{ctes}\\n{select}\\n\"]\n",
    "        if self.ordering:\n",
    "            order_by = \", \".join(str(item) for item in self.ordering)\n",
    "            parts.append(f\"ORDER BY {order_by}\\n\")\n",
    "        if self.limit is not None:\n",
    "            limit = f\"LIMIT {'ALL ' if self.quantifier == 'ALL' else ''}{self.limit}\"\n",
    "            parts.append(limit)\n",
    "        return \"\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c470eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f46c22c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:object of type 'ABCMeta' has no len()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/lab_black.py\", line 206, in format_cell\n",
      "    cell_id = len(self.shell.user_ns[\"In\"]) - 1\n",
      "TypeError: object of type 'ABCMeta' has no len()\n"
     ]
    }
   ],
   "source": [
    "from dj.sql.parsing.backends.antlr4.utils import parse_statement, print_tree, SqlBaseParser as sbp\n",
    "\n",
    "from dj.sql.parsing import ast\n",
    "from dj.sql.parsing.backends.exceptions import DJParseException\n",
    "import antlr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c86b1025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:object of type 'ABCMeta' has no len()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/lab_black.py\", line 206, in format_cell\n",
      "    cell_id = len(self.shell.user_ns[\"In\"]) - 1\n",
      "TypeError: object of type 'ABCMeta' has no len()\n"
     ]
    }
   ],
   "source": [
    "query1 = \"\"\"\n",
    "\n",
    "select\n",
    "\ts_name,\n",
    "\tcount(*) as numwait\n",
    "from\n",
    "\tsupplier,\n",
    "\tlineitem l1,\n",
    "\torders,\n",
    "\tnation\n",
    "where\n",
    "\ts_suppkey = l1.l_suppkey\n",
    "\tand o_orderkey = l1.l_orderkey\n",
    "\tand o_orderstatus = 'F'\n",
    "\tand l1.l_receiptdate > l1.l_commitdate\n",
    "\tand exists (\n",
    "\t\tselect\n",
    "\t\t\t*\n",
    "\t\tfrom\n",
    "\t\t\tlineitem l2\n",
    "\t\twhere\n",
    "\t\t\tl2.l_orderkey = l1.l_orderkey\n",
    "\t\t\tand l2.l_suppkey <> l1.l_suppkey\n",
    "\t)\n",
    "\tand not exists (\n",
    "\t\tselect\n",
    "\t\t\t*\n",
    "\t\tfrom\n",
    "\t\t\tlineitem l3\n",
    "\t\twhere\n",
    "\t\t\tl3.l_orderkey = l1.l_orderkey\n",
    "\t\t\tand l3.l_suppkey <> l1.l_suppkey\n",
    "\t\t\tand l3.l_receiptdate > l3.l_commitdate\n",
    "\t)\n",
    "\tand s_nationkey = n_nationkey\n",
    "\tand n_name = ':1'\n",
    "group by\n",
    "\ts_name\n",
    "order by\n",
    "\tnumwait desc,\n",
    "\ts_name\n",
    "LIMIT 100;\n",
    "\"\"\"\n",
    "\n",
    "query2=\"\"\"\n",
    "WITH sales_by_country AS (\n",
    "    SELECT country, SUM(amount) AS total_sales\n",
    "    FROM sales\n",
    "    GROUP BY country\n",
    "),\n",
    "top_countries AS (\n",
    "    SELECT country, total_sales\n",
    "    FROM sales_by_country\n",
    "    ORDER BY total_sales DESC\n",
    "    LIMIT 3\n",
    ")\n",
    "SELECT *\n",
    "FROM customers\n",
    "WHERE country IN (\n",
    "    SELECT country\n",
    "    FROM top_countries\n",
    ")\n",
    "UNION\n",
    "SELECT *\n",
    "FROM customers\n",
    "WHERE country NOT IN (\n",
    "    SELECT country\n",
    "    FROM top_countries\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88af2c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:object of type 'ABCMeta' has no len()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/lab_black.py\", line 206, in format_cell\n",
      "    cell_id = len(self.shell.user_ns[\"In\"]) - 1\n",
      "TypeError: object of type 'ABCMeta' has no len()\n"
     ]
    }
   ],
   "source": [
    "tree = parse_statement(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6eaf124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dj.sql.parsing.backends.antlr4.grammar.generated.SqlBaseParser.SqlBaseParser.SingleStatementContext at 0x405ab7b1b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:object of type 'ABCMeta' has no len()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/lab_black.py\", line 206, in format_cell\n",
      "    cell_id = len(self.shell.user_ns[\"In\"]) - 1\n",
      "TypeError: object of type 'ABCMeta' has no len()\n"
     ]
    }
   ],
   "source": [
    "parse_statement('select x from a;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2008b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|SingleStatementContext\n",
      "|-StatementDefaultContext\n",
      "|--QueryContext\n",
      "|---QueryTermDefaultContext\n",
      "|----QueryPrimaryDefaultContext\n",
      "|-----RegularQuerySpecificationContext\n",
      "|------SelectClauseContext\n",
      "|-------TerminalNodeImpl[select]\n",
      "|-------NamedExpressionSeqContext\n",
      "|--------NamedExpressionContext\n",
      "|---------ExpressionContext\n",
      "|----------PredicatedContext\n",
      "|-----------ValueExpressionDefaultContext\n",
      "|------------ColumnReferenceContext\n",
      "|-------------IdentifierContext\n",
      "|--------------UnquotedIdentifierContext\n",
      "|---------------TerminalNodeImpl[s_name]\n",
      "|--------TerminalNodeImpl[,]\n",
      "|--------NamedExpressionContext\n",
      "|---------ExpressionContext\n",
      "|----------PredicatedContext\n",
      "|-----------ValueExpressionDefaultContext\n",
      "|------------FunctionCallContext\n",
      "|-------------FunctionNameContext\n",
      "|--------------QualifiedNameContext\n",
      "|---------------IdentifierContext\n",
      "|----------------UnquotedIdentifierContext\n",
      "|-----------------TerminalNodeImpl[count]\n",
      "|-------------TerminalNodeImpl[(]\n",
      "|-------------ExpressionContext\n",
      "|--------------PredicatedContext\n",
      "|---------------ValueExpressionDefaultContext\n",
      "|----------------StarContext\n",
      "|-----------------TerminalNodeImpl[*]\n",
      "|-------------TerminalNodeImpl[)]\n",
      "|---------TerminalNodeImpl[as]\n",
      "|---------ErrorCapturingIdentifierContext\n",
      "|----------IdentifierContext\n",
      "|-----------UnquotedIdentifierContext\n",
      "|------------TerminalNodeImpl[numwait]\n",
      "|----------RealIdentContext\n",
      "|------FromClauseContext\n",
      "|-------TerminalNodeImpl[from]\n",
      "|-------RelationContext\n",
      "|--------TableNameContext\n",
      "|---------MultipartIdentifierContext\n",
      "|----------ErrorCapturingIdentifierContext\n",
      "|-----------IdentifierContext\n",
      "|------------UnquotedIdentifierContext\n",
      "|-------------TerminalNodeImpl[supplier]\n",
      "|-----------RealIdentContext\n",
      "|---------TableAliasContext\n",
      "|-------TerminalNodeImpl[,]\n",
      "|-------RelationContext\n",
      "|--------TableNameContext\n",
      "|---------MultipartIdentifierContext\n",
      "|----------ErrorCapturingIdentifierContext\n",
      "|-----------IdentifierContext\n",
      "|------------UnquotedIdentifierContext\n",
      "|-------------TerminalNodeImpl[lineitem]\n",
      "|-----------RealIdentContext\n",
      "|---------TableAliasContext\n",
      "|----------UnquotedIdentifierContext\n",
      "|-----------TerminalNodeImpl[l1]\n",
      "|-------TerminalNodeImpl[,]\n",
      "|-------RelationContext\n",
      "|--------TableNameContext\n",
      "|---------MultipartIdentifierContext\n",
      "|----------ErrorCapturingIdentifierContext\n",
      "|-----------IdentifierContext\n",
      "|------------UnquotedIdentifierContext\n",
      "|-------------TerminalNodeImpl[orders]\n",
      "|-----------RealIdentContext\n",
      "|---------TableAliasContext\n",
      "|-------TerminalNodeImpl[,]\n",
      "|-------RelationContext\n",
      "|--------TableNameContext\n",
      "|---------MultipartIdentifierContext\n",
      "|----------ErrorCapturingIdentifierContext\n",
      "|-----------IdentifierContext\n",
      "|------------UnquotedIdentifierContext\n",
      "|-------------TerminalNodeImpl[nation]\n",
      "|-----------RealIdentContext\n",
      "|---------TableAliasContext\n",
      "|------WhereClauseContext\n",
      "|-------TerminalNodeImpl[where]\n",
      "|-------LogicalBinaryContext\n",
      "|--------LogicalBinaryContext\n",
      "|---------LogicalBinaryContext\n",
      "|----------LogicalBinaryContext\n",
      "|-----------LogicalBinaryContext\n",
      "|------------LogicalBinaryContext\n",
      "|-------------LogicalBinaryContext\n",
      "|--------------PredicatedContext\n",
      "|---------------ComparisonContext\n",
      "|----------------ValueExpressionDefaultContext\n",
      "|-----------------ColumnReferenceContext\n",
      "|------------------IdentifierContext\n",
      "|-------------------UnquotedIdentifierContext\n",
      "|--------------------TerminalNodeImpl[s_suppkey]\n",
      "|----------------ComparisonOperatorContext\n",
      "|-----------------TerminalNodeImpl[=]\n",
      "|----------------ValueExpressionDefaultContext\n",
      "|-----------------DereferenceContext\n",
      "|------------------ColumnReferenceContext\n",
      "|-------------------IdentifierContext\n",
      "|--------------------UnquotedIdentifierContext\n",
      "|---------------------TerminalNodeImpl[l1]\n",
      "|------------------TerminalNodeImpl[.]\n",
      "|------------------IdentifierContext\n",
      "|-------------------UnquotedIdentifierContext\n",
      "|--------------------TerminalNodeImpl[l_suppkey]\n",
      "|--------------TerminalNodeImpl[and]\n",
      "|--------------PredicatedContext\n",
      "|---------------ComparisonContext\n",
      "|----------------ValueExpressionDefaultContext\n",
      "|-----------------ColumnReferenceContext\n",
      "|------------------IdentifierContext\n",
      "|-------------------UnquotedIdentifierContext\n",
      "|--------------------TerminalNodeImpl[o_orderkey]\n",
      "|----------------ComparisonOperatorContext\n",
      "|-----------------TerminalNodeImpl[=]\n",
      "|----------------ValueExpressionDefaultContext\n",
      "|-----------------DereferenceContext\n",
      "|------------------ColumnReferenceContext\n",
      "|-------------------IdentifierContext\n",
      "|--------------------UnquotedIdentifierContext\n",
      "|---------------------TerminalNodeImpl[l1]\n",
      "|------------------TerminalNodeImpl[.]\n",
      "|------------------IdentifierContext\n",
      "|-------------------UnquotedIdentifierContext\n",
      "|--------------------TerminalNodeImpl[l_orderkey]\n",
      "|-------------TerminalNodeImpl[and]\n",
      "|-------------PredicatedContext\n",
      "|--------------ComparisonContext\n",
      "|---------------ValueExpressionDefaultContext\n",
      "|----------------ColumnReferenceContext\n",
      "|-----------------IdentifierContext\n",
      "|------------------UnquotedIdentifierContext\n",
      "|-------------------TerminalNodeImpl[o_orderstatus]\n",
      "|---------------ComparisonOperatorContext\n",
      "|----------------TerminalNodeImpl[=]\n",
      "|---------------ValueExpressionDefaultContext\n",
      "|----------------ConstantDefaultContext\n",
      "|-----------------StringLiteralContext\n",
      "|------------------TerminalNodeImpl['F']\n",
      "|------------TerminalNodeImpl[and]\n",
      "|------------PredicatedContext\n",
      "|-------------ComparisonContext\n",
      "|--------------ValueExpressionDefaultContext\n",
      "|---------------DereferenceContext\n",
      "|----------------ColumnReferenceContext\n",
      "|-----------------IdentifierContext\n",
      "|------------------UnquotedIdentifierContext\n",
      "|-------------------TerminalNodeImpl[l1]\n",
      "|----------------TerminalNodeImpl[.]\n",
      "|----------------IdentifierContext\n",
      "|-----------------UnquotedIdentifierContext\n",
      "|------------------TerminalNodeImpl[l_receiptdate]\n",
      "|--------------ComparisonOperatorContext\n",
      "|---------------TerminalNodeImpl[>]\n",
      "|--------------ValueExpressionDefaultContext\n",
      "|---------------DereferenceContext\n",
      "|----------------ColumnReferenceContext\n",
      "|-----------------IdentifierContext\n",
      "|------------------UnquotedIdentifierContext\n",
      "|-------------------TerminalNodeImpl[l1]\n",
      "|----------------TerminalNodeImpl[.]\n",
      "|----------------IdentifierContext\n",
      "|-----------------UnquotedIdentifierContext\n",
      "|------------------TerminalNodeImpl[l_commitdate]\n",
      "|-----------TerminalNodeImpl[and]\n",
      "|-----------ExistsContext\n",
      "|------------TerminalNodeImpl[exists]\n",
      "|------------TerminalNodeImpl[(]\n",
      "|------------QueryContext\n",
      "|-------------QueryTermDefaultContext\n",
      "|--------------QueryPrimaryDefaultContext\n",
      "|---------------RegularQuerySpecificationContext\n",
      "|----------------SelectClauseContext\n",
      "|-----------------TerminalNodeImpl[select]\n",
      "|-----------------NamedExpressionSeqContext\n",
      "|------------------NamedExpressionContext\n",
      "|-------------------ExpressionContext\n",
      "|--------------------PredicatedContext\n",
      "|---------------------ValueExpressionDefaultContext\n",
      "|----------------------StarContext\n",
      "|-----------------------TerminalNodeImpl[*]\n",
      "|----------------FromClauseContext\n",
      "|-----------------TerminalNodeImpl[from]\n",
      "|-----------------RelationContext\n",
      "|------------------TableNameContext\n",
      "|-------------------MultipartIdentifierContext\n",
      "|--------------------ErrorCapturingIdentifierContext\n",
      "|---------------------IdentifierContext\n",
      "|----------------------UnquotedIdentifierContext\n",
      "|-----------------------TerminalNodeImpl[lineitem]\n",
      "|---------------------RealIdentContext\n",
      "|-------------------TableAliasContext\n",
      "|--------------------UnquotedIdentifierContext\n",
      "|---------------------TerminalNodeImpl[l2]\n",
      "|----------------WhereClauseContext\n",
      "|-----------------TerminalNodeImpl[where]\n",
      "|-----------------LogicalBinaryContext\n",
      "|------------------PredicatedContext\n",
      "|-------------------ComparisonContext\n",
      "|--------------------ValueExpressionDefaultContext\n",
      "|---------------------DereferenceContext\n",
      "|----------------------ColumnReferenceContext\n",
      "|-----------------------IdentifierContext\n",
      "|------------------------UnquotedIdentifierContext\n",
      "|-------------------------TerminalNodeImpl[l2]\n",
      "|----------------------TerminalNodeImpl[.]\n",
      "|----------------------IdentifierContext\n",
      "|-----------------------UnquotedIdentifierContext\n",
      "|------------------------TerminalNodeImpl[l_orderkey]\n",
      "|--------------------ComparisonOperatorContext\n",
      "|---------------------TerminalNodeImpl[=]\n",
      "|--------------------ValueExpressionDefaultContext\n",
      "|---------------------DereferenceContext\n",
      "|----------------------ColumnReferenceContext\n",
      "|-----------------------IdentifierContext\n",
      "|------------------------UnquotedIdentifierContext\n",
      "|-------------------------TerminalNodeImpl[l1]\n",
      "|----------------------TerminalNodeImpl[.]\n",
      "|----------------------IdentifierContext\n",
      "|-----------------------UnquotedIdentifierContext\n",
      "|------------------------TerminalNodeImpl[l_orderkey]\n",
      "|------------------TerminalNodeImpl[and]\n",
      "|------------------PredicatedContext\n",
      "|-------------------ComparisonContext\n",
      "|--------------------ValueExpressionDefaultContext\n",
      "|---------------------DereferenceContext\n",
      "|----------------------ColumnReferenceContext\n",
      "|-----------------------IdentifierContext\n",
      "|------------------------UnquotedIdentifierContext\n",
      "|-------------------------TerminalNodeImpl[l2]\n",
      "|----------------------TerminalNodeImpl[.]\n",
      "|----------------------IdentifierContext\n",
      "|-----------------------UnquotedIdentifierContext\n",
      "|------------------------TerminalNodeImpl[l_suppkey]\n",
      "|--------------------ComparisonOperatorContext\n",
      "|---------------------TerminalNodeImpl[<>]\n",
      "|--------------------ValueExpressionDefaultContext\n",
      "|---------------------DereferenceContext\n",
      "|----------------------ColumnReferenceContext\n",
      "|-----------------------IdentifierContext\n",
      "|------------------------UnquotedIdentifierContext\n",
      "|-------------------------TerminalNodeImpl[l1]\n",
      "|----------------------TerminalNodeImpl[.]\n",
      "|----------------------IdentifierContext\n",
      "|-----------------------UnquotedIdentifierContext\n",
      "|------------------------TerminalNodeImpl[l_suppkey]\n",
      "|-------------QueryOrganizationContext\n",
      "|------------TerminalNodeImpl[)]\n",
      "|----------TerminalNodeImpl[and]\n",
      "|----------LogicalNotContext\n",
      "|-----------TerminalNodeImpl[not]\n",
      "|-----------ExistsContext\n",
      "|------------TerminalNodeImpl[exists]\n",
      "|------------TerminalNodeImpl[(]\n",
      "|------------QueryContext\n",
      "|-------------QueryTermDefaultContext\n",
      "|--------------QueryPrimaryDefaultContext\n",
      "|---------------RegularQuerySpecificationContext\n",
      "|----------------SelectClauseContext\n",
      "|-----------------TerminalNodeImpl[select]\n",
      "|-----------------NamedExpressionSeqContext\n",
      "|------------------NamedExpressionContext\n",
      "|-------------------ExpressionContext\n",
      "|--------------------PredicatedContext\n",
      "|---------------------ValueExpressionDefaultContext\n",
      "|----------------------StarContext\n",
      "|-----------------------TerminalNodeImpl[*]\n",
      "|----------------FromClauseContext\n",
      "|-----------------TerminalNodeImpl[from]\n",
      "|-----------------RelationContext\n",
      "|------------------TableNameContext\n",
      "|-------------------MultipartIdentifierContext\n",
      "|--------------------ErrorCapturingIdentifierContext\n",
      "|---------------------IdentifierContext\n",
      "|----------------------UnquotedIdentifierContext\n",
      "|-----------------------TerminalNodeImpl[lineitem]\n",
      "|---------------------RealIdentContext\n",
      "|-------------------TableAliasContext\n",
      "|--------------------UnquotedIdentifierContext\n",
      "|---------------------TerminalNodeImpl[l3]\n",
      "|----------------WhereClauseContext\n",
      "|-----------------TerminalNodeImpl[where]\n",
      "|-----------------LogicalBinaryContext\n",
      "|------------------LogicalBinaryContext\n",
      "|-------------------PredicatedContext\n",
      "|--------------------ComparisonContext\n",
      "|---------------------ValueExpressionDefaultContext\n",
      "|----------------------DereferenceContext\n",
      "|-----------------------ColumnReferenceContext\n",
      "|------------------------IdentifierContext\n",
      "|-------------------------UnquotedIdentifierContext\n",
      "|--------------------------TerminalNodeImpl[l3]\n",
      "|-----------------------TerminalNodeImpl[.]\n",
      "|-----------------------IdentifierContext\n",
      "|------------------------UnquotedIdentifierContext\n",
      "|-------------------------TerminalNodeImpl[l_orderkey]\n",
      "|---------------------ComparisonOperatorContext\n",
      "|----------------------TerminalNodeImpl[=]\n",
      "|---------------------ValueExpressionDefaultContext\n",
      "|----------------------DereferenceContext\n",
      "|-----------------------ColumnReferenceContext\n",
      "|------------------------IdentifierContext\n",
      "|-------------------------UnquotedIdentifierContext\n",
      "|--------------------------TerminalNodeImpl[l1]\n",
      "|-----------------------TerminalNodeImpl[.]\n",
      "|-----------------------IdentifierContext\n",
      "|------------------------UnquotedIdentifierContext\n",
      "|-------------------------TerminalNodeImpl[l_orderkey]\n",
      "|-------------------TerminalNodeImpl[and]\n",
      "|-------------------PredicatedContext\n",
      "|--------------------ComparisonContext\n",
      "|---------------------ValueExpressionDefaultContext\n",
      "|----------------------DereferenceContext\n",
      "|-----------------------ColumnReferenceContext\n",
      "|------------------------IdentifierContext\n",
      "|-------------------------UnquotedIdentifierContext\n",
      "|--------------------------TerminalNodeImpl[l3]\n",
      "|-----------------------TerminalNodeImpl[.]\n",
      "|-----------------------IdentifierContext\n",
      "|------------------------UnquotedIdentifierContext\n",
      "|-------------------------TerminalNodeImpl[l_suppkey]\n",
      "|---------------------ComparisonOperatorContext\n",
      "|----------------------TerminalNodeImpl[<>]\n",
      "|---------------------ValueExpressionDefaultContext\n",
      "|----------------------DereferenceContext\n",
      "|-----------------------ColumnReferenceContext\n",
      "|------------------------IdentifierContext\n",
      "|-------------------------UnquotedIdentifierContext\n",
      "|--------------------------TerminalNodeImpl[l1]\n",
      "|-----------------------TerminalNodeImpl[.]\n",
      "|-----------------------IdentifierContext\n",
      "|------------------------UnquotedIdentifierContext\n",
      "|-------------------------TerminalNodeImpl[l_suppkey]\n",
      "|------------------TerminalNodeImpl[and]\n",
      "|------------------PredicatedContext\n",
      "|-------------------ComparisonContext\n",
      "|--------------------ValueExpressionDefaultContext\n",
      "|---------------------DereferenceContext\n",
      "|----------------------ColumnReferenceContext\n",
      "|-----------------------IdentifierContext\n",
      "|------------------------UnquotedIdentifierContext\n",
      "|-------------------------TerminalNodeImpl[l3]\n",
      "|----------------------TerminalNodeImpl[.]\n",
      "|----------------------IdentifierContext\n",
      "|-----------------------UnquotedIdentifierContext\n",
      "|------------------------TerminalNodeImpl[l_receiptdate]\n",
      "|--------------------ComparisonOperatorContext\n",
      "|---------------------TerminalNodeImpl[>]\n",
      "|--------------------ValueExpressionDefaultContext\n",
      "|---------------------DereferenceContext\n",
      "|----------------------ColumnReferenceContext\n",
      "|-----------------------IdentifierContext\n",
      "|------------------------UnquotedIdentifierContext\n",
      "|-------------------------TerminalNodeImpl[l3]\n",
      "|----------------------TerminalNodeImpl[.]\n",
      "|----------------------IdentifierContext\n",
      "|-----------------------UnquotedIdentifierContext\n",
      "|------------------------TerminalNodeImpl[l_commitdate]\n",
      "|-------------QueryOrganizationContext\n",
      "|------------TerminalNodeImpl[)]\n",
      "|---------TerminalNodeImpl[and]\n",
      "|---------PredicatedContext\n",
      "|----------ComparisonContext\n",
      "|-----------ValueExpressionDefaultContext\n",
      "|------------ColumnReferenceContext\n",
      "|-------------IdentifierContext\n",
      "|--------------UnquotedIdentifierContext\n",
      "|---------------TerminalNodeImpl[s_nationkey]\n",
      "|-----------ComparisonOperatorContext\n",
      "|------------TerminalNodeImpl[=]\n",
      "|-----------ValueExpressionDefaultContext\n",
      "|------------ColumnReferenceContext\n",
      "|-------------IdentifierContext\n",
      "|--------------UnquotedIdentifierContext\n",
      "|---------------TerminalNodeImpl[n_nationkey]\n",
      "|--------TerminalNodeImpl[and]\n",
      "|--------PredicatedContext\n",
      "|---------ComparisonContext\n",
      "|----------ValueExpressionDefaultContext\n",
      "|-----------ColumnReferenceContext\n",
      "|------------IdentifierContext\n",
      "|-------------UnquotedIdentifierContext\n",
      "|--------------TerminalNodeImpl[n_name]\n",
      "|----------ComparisonOperatorContext\n",
      "|-----------TerminalNodeImpl[=]\n",
      "|----------ValueExpressionDefaultContext\n",
      "|-----------ConstantDefaultContext\n",
      "|------------StringLiteralContext\n",
      "|-------------TerminalNodeImpl[':1']\n",
      "|------AggregationClauseContext\n",
      "|-------TerminalNodeImpl[group]\n",
      "|-------TerminalNodeImpl[by]\n",
      "|-------ExpressionContext\n",
      "|--------PredicatedContext\n",
      "|---------ValueExpressionDefaultContext\n",
      "|----------ColumnReferenceContext\n",
      "|-----------IdentifierContext\n",
      "|------------UnquotedIdentifierContext\n",
      "|-------------TerminalNodeImpl[s_name]\n",
      "|---QueryOrganizationContext\n",
      "|----TerminalNodeImpl[order]\n",
      "|----TerminalNodeImpl[by]\n",
      "|----SortItemContext\n",
      "|-----ExpressionContext\n",
      "|------PredicatedContext\n",
      "|-------ValueExpressionDefaultContext\n",
      "|--------ColumnReferenceContext\n",
      "|---------IdentifierContext\n",
      "|----------UnquotedIdentifierContext\n",
      "|-----------TerminalNodeImpl[numwait]\n",
      "|-----TerminalNodeImpl[desc]\n",
      "|----TerminalNodeImpl[,]\n",
      "|----SortItemContext\n",
      "|-----ExpressionContext\n",
      "|------PredicatedContext\n",
      "|-------ValueExpressionDefaultContext\n",
      "|--------ColumnReferenceContext\n",
      "|---------IdentifierContext\n",
      "|----------UnquotedIdentifierContext\n",
      "|-----------TerminalNodeImpl[s_name]\n",
      "|----TerminalNodeImpl[LIMIT]\n",
      "|----ExpressionContext\n",
      "|-----PredicatedContext\n",
      "|------ValueExpressionDefaultContext\n",
      "|-------ConstantDefaultContext\n",
      "|--------NumericLiteralContext\n",
      "|---------IntegerLiteralContext\n",
      "|----------TerminalNodeImpl[100]\n",
      "|-TerminalNodeImpl[;]\n",
      "|-TerminalNodeImpl[<EOF>]\n"
     ]
    }
   ],
   "source": [
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8b69e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:object of type 'ABCMeta' has no len()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/lab_black.py\", line 206, in format_cell\n",
      "    cell_id = len(self.shell.user_ns[\"In\"]) - 1\n",
      "TypeError: object of type 'ABCMeta' has no len()\n"
     ]
    }
   ],
   "source": [
    "# highest signature: visit(tree) -> Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2534a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import singledispatch\n",
    "\n",
    "@singledispatch\n",
    "def visit(ctx):\n",
    "    raise DJParseException(f\"Could not parse {ctx}\")\n",
    "    \n",
    "@visit.register\n",
    "def _(ctx: sbp.SingleStatementContext):\n",
    "    return visit(ctx.statement())\n",
    "\n",
    "@visit.register\n",
    "def _(ctx: sbp.StatementDefaultContext):\n",
    "    return visit(ctx.query())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "263df9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp.QueryContext??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1731254e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (156694667.py, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[5], line 32\u001B[0;36m\u001B[0m\n\u001B[0;31m    )\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "@visit.register\n",
    "def _(ctx: sbp.QueryContext):\n",
    "\n",
    "    \n",
    "    ctes = []\n",
    "    if ctes_ctx:=self.ctes():\n",
    "        ctes = visit(ctes_ctx)\n",
    "        \n",
    "    #TODO: orgs move from ast.Select to ast.Query\n",
    "    if orgs_ctx:=self.queryOrganization():\n",
    "        orgs = visit(orgs_ctx)\n",
    "    queryTerm(self)\n",
    "    \n",
    "    return ast.Query(\n",
    "        ctes=ctes,\n",
    "        select=select,\n",
    "        set_ops\n",
    "    )\n",
    "\n",
    "@visit.register\n",
    "def _(ctx: sbp.QueryTermContext):\n",
    "    return select, []\n",
    "\n",
    "@visit.register\n",
    "def _(ctx: sbp.CtesContext):\n",
    "    ...\n",
    "    \n",
    "@visit.register\n",
    "def _(ctx: sbp.QueryOrganizationContext):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e02f8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sbp.QualifiedNameContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ffc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@visit.register\n",
    "def _(ctx: sbp.FromClauseContext):\n",
    "    tables = [visit(relation) for relation in ctx.relation()]\n",
    "    joins = [visit(join) for join in ctx.joinRelation()]\n",
    "    return From(tables=tables, joins=joins)\n",
    "\n",
    "@visit.register\n",
    "def _(ctx: sbp.JoinRelationContext):\n",
    "    join_type = ctx.joinType().getText() if ctx.joinType() else \"\"\n",
    "    right = visit(ctx.relationPrimary())\n",
    "    criteria = visit(ctx.joinCriteria()) if ctx.joinCriteria() else None\n",
    "    return Join(join_type=join_type, table=right, criteria=criteria)\n",
    "\n",
    "@visit.register\n",
    "def _(ctx: sbp.JoinCriteriaContext):\n",
    "    if ctx.ON():\n",
    "        on_expr = visit(ctx.booleanExpression())\n",
    "        return JoinCriteria(on=on_expr)\n",
    "    elif ctx.USING():\n",
    "        id_list = [visit(ident) for ident in ctx.identifierList().identifier()]\n",
    "        return JoinCriteria(using=id_list)\n",
    "\n",
    "@visit.register\n",
    "def _(ctx: sbp.IdentifierContext):\n",
    "    return Identifier(name=ctx.getText())\n",
    "\n",
    "@visit.register\n",
    "def _(ctx: sbp.QualifiedNameContext):\n",
    "    parts = [visit(ident) for ident in ctx.identifier()]\n",
    "    return QualifiedName(parts=parts)\n",
    "\n",
    "@visit.register\n",
    "def _(ctx: sbp.LateralViewContext):\n",
    "    outer = bool(ctx.OUTER())\n",
    "    func_name = visit(ctx.qualifiedName())\n",
    "    args = [visit(expr) for expr in ctx.expression()] if ctx.expression() else []\n",
    "    table_name = visit(ctx.tblName)\n",
    "    col_names = [visit(ident) for ident in ctx.identifier()] if ctx.identifier() else []\n",
    "    return LateralView(outer=outer, func_name=func_name, args=args, table_name=table_name, col_names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad222d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
